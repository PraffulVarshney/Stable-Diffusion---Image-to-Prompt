# Stable-Diffusion---Image-to-Prompt
## Problem Statement
The popularity of text-to-image models has spurned an entire new field of prompt engineering. Part art and part unsettled science, ML practitioners and researchers are rapidly grappling with understanding the relationships between prompts and the images they generate and in this project we aim to reverse the typical direction of a generative text-to-image model: instead of generating an image from a text prompt, can you create a model which can predict the text prompt given a generated image? You will make predictions on a dataset containing a wide variety of (prompt, image) pairs generated by Stable Diffusion 2.0, in order to understand how reversible the latent relationship is.



### References
  - Show and Tell: A Neural Image Caption Generator  (https://arxiv.org/abs/1411.4555) <br/>
  - Tensorflow Tutorials<br/>
  This project is done under the guidance of Vision And Language Group @IIT Roorkee

### Contributers
  <a href="https://github.com/praffulv-225">Prafful Varshney</a><br/>
